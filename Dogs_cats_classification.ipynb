{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dogs_cats_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IxuZ4D6L6QtZJiG6jlspYEOM8YAsjLhw",
      "authorship_tag": "ABX9TyNrzuAGeyUGk6rYiXzWvZPj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakshu2810/Dogs_cats_classification/blob/main/Dogs_cats_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcoH-bXsuLnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01bf792-eea6-4411-a134-d5a1e362c1a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txXQKDnVvFbz"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcLkBoKRZRXB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eH243wf9wVk"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fOdaijG26m6"
      },
      "source": [
        "# Preprocessing the Train set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8NkzgC30NVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f450626c-694b-4c4a-c2ef-a95f39be6995"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range =0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip =True)\n",
        "training_set = train_datagen.flow_from_directory('Dataset/training_set',\n",
        "                                                 target_size =(64,64),\n",
        "                                                 batch_size =32,\n",
        "                                                 class_mode ='binary')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8005 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37XLamjC2y53"
      },
      "source": [
        "# Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx801s2h1bY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f0b4cd-18ab-4a65-8873-af7804ff15a5"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('Dataset/test_set',\n",
        "                                                 target_size =(64,64),\n",
        "                                                 batch_size =32,\n",
        "                                                 class_mode ='binary')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2023 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J41wAhI53DrA"
      },
      "source": [
        "# Part 2 - Building the CNN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-ZL5KrS3Qyn"
      },
      "source": [
        "# Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb4H5dem3XKA"
      },
      "source": [
        "cnn= tf.keras.models.Sequential()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyR6Kwvs3gt-"
      },
      "source": [
        "# Step 1- Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZnP3qKn3raw"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3 , activation = 'relu',input_shape=[64,64,3]))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdFFuAVpLdWz"
      },
      "source": [
        "# Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yckLnroY3e15"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 , strides=2))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JOrpAzJLoCr"
      },
      "source": [
        "# Adding a asecond convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTtrhcTv2CXE"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahCb0Xa2Lzw3"
      },
      "source": [
        "# Step 3  - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBe1DVKvLxpp"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEfdQEJ_L7DA"
      },
      "source": [
        "# Step 4- Full connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tyypI-VLyeS"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSa7gOJwNmTH"
      },
      "source": [
        "# Step 5 - Output layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw7RPJwyNhT3"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j06ovngQMJfK"
      },
      "source": [
        "#Part 3 - Training CNN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIoh4euTOJMT"
      },
      "source": [
        "# Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9A6smoTLysv"
      },
      "source": [
        "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Pgw6kVOOmJ"
      },
      "source": [
        "# Training the CNN on the training set and evaluting it on Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uPQ53pON4ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031fca0c-836b-4264-8058-b7c97b9e3995"
      },
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set,epochs = 20)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "251/251 [==============================] - 67s 268ms/step - loss: 0.5806 - accuracy: 0.6988 - val_loss: 0.5453 - val_accuracy: 0.7301\n",
            "Epoch 2/20\n",
            "251/251 [==============================] - 68s 270ms/step - loss: 0.5422 - accuracy: 0.7223 - val_loss: 0.5229 - val_accuracy: 0.7410\n",
            "Epoch 3/20\n",
            "251/251 [==============================] - 68s 270ms/step - loss: 0.5150 - accuracy: 0.7434 - val_loss: 0.5070 - val_accuracy: 0.7652\n",
            "Epoch 4/20\n",
            "251/251 [==============================] - 67s 267ms/step - loss: 0.4999 - accuracy: 0.7568 - val_loss: 0.4837 - val_accuracy: 0.7672\n",
            "Epoch 5/20\n",
            "251/251 [==============================] - 67s 267ms/step - loss: 0.4664 - accuracy: 0.7750 - val_loss: 0.4629 - val_accuracy: 0.7825\n",
            "Epoch 6/20\n",
            "251/251 [==============================] - 68s 269ms/step - loss: 0.4636 - accuracy: 0.7806 - val_loss: 0.4706 - val_accuracy: 0.7815\n",
            "Epoch 7/20\n",
            "251/251 [==============================] - 67s 268ms/step - loss: 0.4372 - accuracy: 0.7921 - val_loss: 0.4953 - val_accuracy: 0.7716\n",
            "Epoch 8/20\n",
            "251/251 [==============================] - 67s 268ms/step - loss: 0.4288 - accuracy: 0.8001 - val_loss: 0.4596 - val_accuracy: 0.7879\n",
            "Epoch 9/20\n",
            "251/251 [==============================] - 67s 268ms/step - loss: 0.4258 - accuracy: 0.8017 - val_loss: 0.4462 - val_accuracy: 0.7973\n",
            "Epoch 10/20\n",
            "251/251 [==============================] - 67s 268ms/step - loss: 0.4104 - accuracy: 0.8104 - val_loss: 0.4391 - val_accuracy: 0.8008\n",
            "Epoch 11/20\n",
            "251/251 [==============================] - 67s 267ms/step - loss: 0.3962 - accuracy: 0.8155 - val_loss: 0.4357 - val_accuracy: 0.8033\n",
            "Epoch 12/20\n",
            "251/251 [==============================] - 67s 266ms/step - loss: 0.3929 - accuracy: 0.8176 - val_loss: 0.4582 - val_accuracy: 0.7988\n",
            "Epoch 13/20\n",
            "251/251 [==============================] - 67s 265ms/step - loss: 0.3787 - accuracy: 0.8289 - val_loss: 0.4629 - val_accuracy: 0.7949\n",
            "Epoch 14/20\n",
            "251/251 [==============================] - 67s 266ms/step - loss: 0.3730 - accuracy: 0.8332 - val_loss: 0.4679 - val_accuracy: 0.7954\n",
            "Epoch 15/20\n",
            "251/251 [==============================] - 67s 267ms/step - loss: 0.3652 - accuracy: 0.8354 - val_loss: 0.4670 - val_accuracy: 0.7909\n",
            "Epoch 16/20\n",
            "251/251 [==============================] - 67s 268ms/step - loss: 0.3488 - accuracy: 0.8455 - val_loss: 0.4489 - val_accuracy: 0.7949\n",
            "Epoch 17/20\n",
            "251/251 [==============================] - 67s 266ms/step - loss: 0.3409 - accuracy: 0.8476 - val_loss: 0.5014 - val_accuracy: 0.8023\n",
            "Epoch 18/20\n",
            "251/251 [==============================] - 67s 265ms/step - loss: 0.3346 - accuracy: 0.8532 - val_loss: 0.4815 - val_accuracy: 0.8018\n",
            "Epoch 19/20\n",
            "251/251 [==============================] - 66s 264ms/step - loss: 0.3200 - accuracy: 0.8565 - val_loss: 0.4432 - val_accuracy: 0.8112\n",
            "Epoch 20/20\n",
            "251/251 [==============================] - 67s 265ms/step - loss: 0.3239 - accuracy: 0.8588 - val_loss: 0.4447 - val_accuracy: 0.8141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29d5104910>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epy1X2QiPE4x"
      },
      "source": [
        "# Part 4- Making a Single Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO4_lZiFN4Oa"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image= image.load_img('Dataset/single_prediction/dog_cat.4008.jpg',target_size=(64,64))\n",
        "test_image= image.img_to_array(test_image)\n",
        "test_image= np.expand_dims(test_image,axis=0)\n",
        "result=cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "   prediction ='dog'\n",
        "else:\n",
        "   prediction ='cat'"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bu92OpRN4Lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed1b2a5-2fd2-49ab-be86-db2336db8454"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}